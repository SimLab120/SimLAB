{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_path = '/home/simlab120/Denoise_comp/Pragyant/image-impeccable-train-data-part1/42487393/seismic_w_noise_vol_42487393.npy'\n",
    "y_train_path = '/home/simlab120/Denoise_comp/Pragyant/image-impeccable-train-data-part1/42487393/seismicCubes_RFC_fullstack_2024.42487393.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (1259,300,300)\n",
    "# load the data\n",
    "# make the data in 2d section\n",
    "# make the train set and test set\n",
    "# print the image also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch\n",
    "# 2 files\n",
    "# 1259*300*300 ---> 1259*300 in 300 images\n",
    "# x,y load\n",
    "# x,y sub sample\n",
    "# pair\n",
    "# return\n",
    "class volDataset(Dataset):\n",
    "    def __init__(self, x_slices, y_slices, transform=None):\n",
    "        \"\"\"\n",
    "        x_slices: List of noisy seismic slices (each of shape 1259x300)\n",
    "        y_slices: List of clean seismic slices (each of shape 1259x300)\n",
    "        \"\"\"\n",
    "        self.x_slices = x_slices\n",
    "        self.y_slices = y_slices\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_slices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns one slice (1, 1259, 300)\"\"\"\n",
    "        x_slice = torch.tensor(self.x_slices[idx], dtype=torch.float32).unsqueeze(0)  # (1, 1259, 300)\n",
    "        y_slice = torch.tensor(self.y_slices[idx], dtype=torch.float32).unsqueeze(0)  # (1, 1259, 300)\n",
    "\n",
    "        if self.transform:\n",
    "            x_slice = self.transform(x_slice)\n",
    "            y_slice = self.transform(y_slice)\n",
    "\n",
    "        return x_slice, y_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Batch Shape: torch.Size([8, 1, 1259, 300]) torch.Size([8, 1, 1259, 300])\n",
      "Test Batch Shape: torch.Size([8, 1, 1259, 300]) torch.Size([8, 1, 1259, 300])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Convert volume to 2D slices\n",
    "# Load seismic volumes\n",
    "X_volume = np.load('/home/simlab120/Denoise_comp/Pragyant/image-impeccable-train-data-part1/42487393/seismic_w_noise_vol_42487393.npy',allow_pickle=True)  # (1259, 300, 300)\n",
    "y_volume = np.load('/home/simlab120/Denoise_comp/Pragyant/image-impeccable-train-data-part1/42487393/seismicCubes_RFC_fullstack_2024.42487393.npy',allow_pickle=True)  # (1259, 300, 300)\n",
    "\n",
    "# Convert volume to 2D slices\n",
    "\n",
    "X_slices = [X_volume[:, :, i] for i in range(X_volume.shape[2])]  # List of 300 slices\n",
    "y_slices = [y_volume[:, :, i] for i in range(y_volume.shape[2])]  # List of 300 slices\n",
    "\n",
    "# Train-test split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_slices, y_slices, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = volDataset(X_train, y_train)\n",
    "test_dataset = volDataset(X_test, y_test)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Check batch shapes\n",
    "for x_batch, y_batch in train_loader:\n",
    "    print(\"Train Batch Shape:\", x_batch.shape, y_batch.shape)  # Expected: (8, 1, 1259, 300)\n",
    "    break\n",
    "for x_batch, y_batch in test_loader:\n",
    "    print(\"Test Batch Shape:\", x_batch.shape, y_batch.shape)  # Expected: (8, 1, 1259, 300)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1259, 300])\n"
     ]
    }
   ],
   "source": [
    "class cnn_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn_model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=64, out_channels=1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.cnn_model(x)\n",
    "    \n",
    "model = cnn_model()\n",
    "x = torch.randn(1,1,1259,300)\n",
    "output = model(x)\n",
    "\n",
    "print(output.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torcheval in /home/simlab120/anaconda3/envs/torch/lib/python3.12/site-packages (0.0.7)\n",
      "Requirement already satisfied: typing-extensions in /home/simlab120/anaconda3/envs/torch/lib/python3.12/site-packages (from torcheval) (4.11.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torcheval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define model\n",
    "model = cnn_model()\n",
    "\n",
    "# Define Loss Function (MSE for denoising)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define Optimizer (Adam works well)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Batch Shape: torch.Size([8, 1, 1259, 300]) torch.Size([8, 1, 1259, 300])\n"
     ]
    }
   ],
   "source": [
    "# Check batch shapes\n",
    "for x_batch, y_batch in train_loader:\n",
    "    print(\"Train Batch Shape:\", x_batch.shape, y_batch.shape)  # Expected: (batch_size, 1, 1259, 300)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import StructuralSimilarityIndexMeasure\n",
    "ssim_metric = StructuralSimilarityIndexMeasure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 9749.0857, SSIM: 0.4821\n",
      "Epoch [2/200], Loss: 9251.4361, SSIM: 0.4948\n",
      "Epoch [3/200], Loss: 8805.1053, SSIM: 0.4999\n",
      "Epoch [4/200], Loss: 8401.0017, SSIM: 0.5015\n",
      "Epoch [5/200], Loss: 8031.5456, SSIM: 0.5030\n",
      "Epoch [6/200], Loss: 7695.5282, SSIM: 0.5062\n",
      "Epoch [7/200], Loss: 7385.2166, SSIM: 0.5064\n",
      "Epoch [8/200], Loss: 7102.9782, SSIM: 0.5113\n",
      "Epoch [9/200], Loss: 6843.2328, SSIM: 0.5136\n",
      "Epoch [10/200], Loss: 6606.2257, SSIM: 0.5176\n",
      "Epoch [11/200], Loss: 6391.7808, SSIM: 0.5223\n",
      "Epoch [12/200], Loss: 6198.7799, SSIM: 0.5277\n",
      "Epoch [13/200], Loss: 6018.5184, SSIM: 0.5318\n",
      "Epoch [14/200], Loss: 5851.3370, SSIM: 0.5374\n",
      "Epoch [15/200], Loss: 5703.7701, SSIM: 0.5395\n",
      "Epoch [16/200], Loss: 5571.5430, SSIM: 0.5449\n",
      "Epoch [17/200], Loss: 5450.8500, SSIM: 0.5485\n",
      "Epoch [18/200], Loss: 5343.4099, SSIM: 0.5509\n",
      "Epoch [19/200], Loss: 5247.9383, SSIM: 0.5552\n",
      "Epoch [20/200], Loss: 5154.6351, SSIM: 0.5599\n",
      "Epoch [21/200], Loss: 5079.7308, SSIM: 0.5618\n",
      "Epoch [22/200], Loss: 5014.4119, SSIM: 0.5631\n",
      "Epoch [23/200], Loss: 4946.8676, SSIM: 0.5683\n",
      "Epoch [24/200], Loss: 4887.9668, SSIM: 0.5706\n",
      "Epoch [25/200], Loss: 4842.5176, SSIM: 0.5732\n",
      "Epoch [26/200], Loss: 4793.8133, SSIM: 0.5742\n",
      "Epoch [27/200], Loss: 4765.5066, SSIM: 0.5743\n",
      "Epoch [28/200], Loss: 4730.5237, SSIM: 0.5767\n",
      "Epoch [29/200], Loss: 4695.5248, SSIM: 0.5776\n",
      "Epoch [30/200], Loss: 4674.0667, SSIM: 0.5793\n",
      "Epoch [31/200], Loss: 4640.8494, SSIM: 0.5800\n",
      "Epoch [32/200], Loss: 4626.6980, SSIM: 0.5815\n",
      "Epoch [33/200], Loss: 4603.1299, SSIM: 0.5844\n",
      "Epoch [34/200], Loss: 4584.3452, SSIM: 0.5841\n",
      "Epoch [35/200], Loss: 4574.1957, SSIM: 0.5840\n",
      "Epoch [36/200], Loss: 4562.6451, SSIM: 0.5859\n",
      "Epoch [37/200], Loss: 4553.4180, SSIM: 0.5865\n",
      "Epoch [38/200], Loss: 4545.7389, SSIM: 0.5861\n",
      "Epoch [39/200], Loss: 4527.5860, SSIM: 0.5868\n",
      "Epoch [40/200], Loss: 4524.7754, SSIM: 0.5869\n",
      "Epoch [41/200], Loss: 4516.6208, SSIM: 0.5884\n",
      "Epoch [42/200], Loss: 4513.7083, SSIM: 0.5876\n",
      "Epoch [43/200], Loss: 4513.6064, SSIM: 0.5870\n",
      "Epoch [44/200], Loss: 4505.6795, SSIM: 0.5885\n",
      "Epoch [45/200], Loss: 4510.2401, SSIM: 0.5874\n",
      "Epoch [46/200], Loss: 4503.6315, SSIM: 0.5887\n",
      "Epoch [47/200], Loss: 4491.8488, SSIM: 0.5893\n",
      "Epoch [48/200], Loss: 4491.1004, SSIM: 0.5892\n",
      "Epoch [49/200], Loss: 4485.9875, SSIM: 0.5900\n",
      "Epoch [50/200], Loss: 4485.7947, SSIM: 0.5894\n",
      "Epoch [51/200], Loss: 4484.5274, SSIM: 0.5900\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200  # Change as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    running_ssim = 0.0\n",
    "\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "\n",
    "        outputs = model(x_batch)  # Forward pass\n",
    "        loss = criterion(outputs, y_batch)  # Compute loss\n",
    "\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Compute SSIM (detach to avoid tracking gradients)\n",
    "        batch_ssim = ssim_metric(outputs.detach(), y_batch.detach())\n",
    "        running_ssim += batch_ssim.item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Print epoch loss\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}, SSIM: {running_ssim/len(train_loader):.4f}\")\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

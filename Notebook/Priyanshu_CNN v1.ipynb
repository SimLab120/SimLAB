{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_path = '/home/simlab120/Denoise_comp/Pragyant/image-impeccable-train-data-part1/42487393/seismic_w_noise_vol_42487393.npy'\n",
    "y_train_path = '/home/simlab120/Denoise_comp/Pragyant/image-impeccable-train-data-part1/42487393/seismicCubes_RFC_fullstack_2024.42487393.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (1259,300,300)\n",
    "# load the data\n",
    "# make the data in 2d section\n",
    "# make the train set and test set\n",
    "# print the image also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch\n",
    "# 2 files\n",
    "# 1259*300*300 ---> 1259*300 in 300 images\n",
    "# x,y load\n",
    "# x,y sub sample\n",
    "# pair\n",
    "# return\n",
    "class volDataset(Dataset):\n",
    "    def __init__(self, x_slices, y_slices, transform=None):\n",
    "        \"\"\"\n",
    "        x_slices: List of noisy seismic slices (each of shape 1259x300)\n",
    "        y_slices: List of clean seismic slices (each of shape 1259x300)\n",
    "        \"\"\"\n",
    "        self.x_slices = x_slices\n",
    "        self.y_slices = y_slices\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_slices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns one slice (1, 1259, 300)\"\"\"\n",
    "        x_slice = torch.tensor(self.x_slices[idx], dtype=torch.float32).unsqueeze(0)  # (1, 1259, 300)\n",
    "        y_slice = torch.tensor(self.y_slices[idx], dtype=torch.float32).unsqueeze(0)  # (1, 1259, 300)\n",
    "\n",
    "        if self.transform:\n",
    "            x_slice = self.transform(x_slice)\n",
    "            y_slice = self.transform(y_slice)\n",
    "\n",
    "        return x_slice, y_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Batch Shape: torch.Size([8, 1, 1259, 300]) torch.Size([8, 1, 1259, 300])\n",
      "Test Batch Shape: torch.Size([8, 1, 1259, 300]) torch.Size([8, 1, 1259, 300])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Convert volume to 2D slices\n",
    "# Load seismic volumes\n",
    "X_volume = np.load('/home/simlab120/Denoise_comp/Pragyant/image-impeccable-train-data-part1/42487393/seismic_w_noise_vol_42487393.npy',allow_pickle=True)  # (1259, 300, 300)\n",
    "y_volume = np.load('/home/simlab120/Denoise_comp/Pragyant/image-impeccable-train-data-part1/42487393/seismicCubes_RFC_fullstack_2024.42487393.npy',allow_pickle=True)  # (1259, 300, 300)\n",
    "\n",
    "# Convert volume to 2D slices\n",
    "\n",
    "X_slices = [X_volume[:, :, i] for i in range(X_volume.shape[2])]  # List of 300 slices\n",
    "y_slices = [y_volume[:, :, i] for i in range(y_volume.shape[2])]  # List of 300 slices\n",
    "\n",
    "# Train-test split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_slices, y_slices, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = volDataset(X_train, y_train)\n",
    "test_dataset = volDataset(X_test, y_test)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Check batch shapes\n",
    "for x_batch, y_batch in train_loader:\n",
    "    print(\"Train Batch Shape:\", x_batch.shape, y_batch.shape)  # Expected: (8, 1, 1259, 300)\n",
    "    break\n",
    "for x_batch, y_batch in test_loader:\n",
    "    print(\"Test Batch Shape:\", x_batch.shape, y_batch.shape)  # Expected: (8, 1, 1259, 300)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Crop2d(nn.Module):\n",
    "    def __init__(self, left=10, right=10, top=21, bottom=0):\n",
    "        super(Crop2d, self).__init__()\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.top = top\n",
    "        self.bottom = bottom\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, self.top:x.shape[2] - self.bottom, self.left:x.shape[3] - self.right]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1259, 300])\n"
     ]
    }
   ],
   "source": [
    "class cnn_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.cnn_model = nn.Sequential(\n",
    "            nn.ZeroPad2d((10,10,21,0)),\n",
    "            nn.Conv2d(in_channels=1, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),  # Corrected\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=256, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),  # Corrected\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),  # Corrected\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),  # Corrected\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ConvTranspose2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),  # Corrected\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ConvTranspose2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),  # Corrected\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),  # Corrected\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU(),\n",
    "            Crop2d(10, 10, 21, 0),\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.cnn_model(x)\n",
    "    \n",
    "model = cnn_model()\n",
    "x = torch.randn(1,1,1259,300)\n",
    "output = model(x)\n",
    "\n",
    "print(output.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torcheval in ./anaconda3/envs/torch/lib/python3.12/site-packages (0.0.7)\n",
      "Requirement already satisfied: typing-extensions in ./anaconda3/envs/torch/lib/python3.12/site-packages (from torcheval) (4.11.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torcheval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define model\n",
    "model = cnn_model()\n",
    "\n",
    "# Define Loss Function (MSE for denoising)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define Optimizer (Adam works well)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Batch Shape: torch.Size([8, 1, 1259, 300]) torch.Size([8, 1, 1259, 300])\n"
     ]
    }
   ],
   "source": [
    "# Check batch shapes\n",
    "for x_batch, y_batch in train_loader:\n",
    "    print(\"Train Batch Shape:\", x_batch.shape, y_batch.shape)  # Expected: (batch_size, 1, 1259, 300)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simlab120/anaconda3/envs/torch/lib/python3.12/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `StructuralSimilarityIndexMeasure` from `torchmetrics` was deprecated and will be removed in 2.0. Import `StructuralSimilarityIndexMeasure` from `torchmetrics.image` instead.\n",
      "  _future_warning(\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics import StructuralSimilarityIndexMeasure\n",
    "ssim_metric = StructuralSimilarityIndexMeasure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 10034.0754, SSIM: 0.4763\n",
      "Epoch [2/200], Loss: 9583.9085, SSIM: 0.4796\n",
      "Epoch [3/200], Loss: 8972.9845, SSIM: 0.4891\n",
      "Epoch [4/200], Loss: 8429.4526, SSIM: 0.4923\n",
      "Epoch [5/200], Loss: 7921.5783, SSIM: 0.4982\n",
      "Epoch [6/200], Loss: 7479.4518, SSIM: 0.5031\n",
      "Epoch [7/200], Loss: 7094.1503, SSIM: 0.5114\n",
      "Epoch [8/200], Loss: 6732.0171, SSIM: 0.5203\n",
      "Epoch [9/200], Loss: 6416.2509, SSIM: 0.5284\n",
      "Epoch [10/200], Loss: 6132.7325, SSIM: 0.5367\n",
      "Epoch [11/200], Loss: 5894.2965, SSIM: 0.5451\n",
      "Epoch [12/200], Loss: 5674.0245, SSIM: 0.5500\n",
      "Epoch [13/200], Loss: 5486.1499, SSIM: 0.5579\n",
      "Epoch [14/200], Loss: 5305.1999, SSIM: 0.5666\n",
      "Epoch [15/200], Loss: 5150.6497, SSIM: 0.5718\n",
      "Epoch [16/200], Loss: 4997.5051, SSIM: 0.5788\n",
      "Epoch [17/200], Loss: 4892.1826, SSIM: 0.5820\n",
      "Epoch [18/200], Loss: 4781.8391, SSIM: 0.5879\n",
      "Epoch [19/200], Loss: 4677.4684, SSIM: 0.5941\n",
      "Epoch [20/200], Loss: 4613.4869, SSIM: 0.5951\n",
      "Epoch [21/200], Loss: 4512.7434, SSIM: 0.6016\n",
      "Epoch [22/200], Loss: 4449.8108, SSIM: 0.6060\n",
      "Epoch [23/200], Loss: 4412.5092, SSIM: 0.6056\n",
      "Epoch [24/200], Loss: 4355.4739, SSIM: 0.6081\n",
      "Epoch [25/200], Loss: 4313.0122, SSIM: 0.6117\n",
      "Epoch [26/200], Loss: 4284.7725, SSIM: 0.6128\n",
      "Epoch [27/200], Loss: 4254.6413, SSIM: 0.6149\n",
      "Epoch [28/200], Loss: 4212.2134, SSIM: 0.6166\n",
      "Epoch [29/200], Loss: 4189.5973, SSIM: 0.6187\n",
      "Epoch [30/200], Loss: 4181.2540, SSIM: 0.6166\n",
      "Epoch [31/200], Loss: 4148.3158, SSIM: 0.6214\n",
      "Epoch [32/200], Loss: 4152.2699, SSIM: 0.6198\n",
      "Epoch [33/200], Loss: 4135.2680, SSIM: 0.6203\n",
      "Epoch [34/200], Loss: 4126.2133, SSIM: 0.6215\n",
      "Epoch [35/200], Loss: 4134.7396, SSIM: 0.6212\n",
      "Epoch [36/200], Loss: 4090.3228, SSIM: 0.6235\n",
      "Epoch [37/200], Loss: 4079.4185, SSIM: 0.6255\n",
      "Epoch [38/200], Loss: 4077.4232, SSIM: 0.6244\n",
      "Epoch [39/200], Loss: 4070.5843, SSIM: 0.6250\n",
      "Epoch [40/200], Loss: 4071.7851, SSIM: 0.6255\n",
      "Epoch [41/200], Loss: 4062.2444, SSIM: 0.6261\n",
      "Epoch [42/200], Loss: 4059.6862, SSIM: 0.6269\n",
      "Epoch [43/200], Loss: 4057.3493, SSIM: 0.6268\n",
      "Epoch [44/200], Loss: 4046.3543, SSIM: 0.6278\n",
      "Epoch [45/200], Loss: 4069.4971, SSIM: 0.6270\n",
      "Epoch [46/200], Loss: 4070.7881, SSIM: 0.6260\n",
      "Epoch [47/200], Loss: 4046.3606, SSIM: 0.6283\n",
      "Epoch [48/200], Loss: 4036.6822, SSIM: 0.6278\n",
      "Epoch [49/200], Loss: 4035.9351, SSIM: 0.6280\n",
      "Epoch [50/200], Loss: 4038.8044, SSIM: 0.6275\n",
      "Epoch [51/200], Loss: 4031.8763, SSIM: 0.6289\n",
      "Epoch [52/200], Loss: 4031.9483, SSIM: 0.6298\n",
      "Epoch [53/200], Loss: 4033.6167, SSIM: 0.6294\n",
      "Epoch [54/200], Loss: 4038.1762, SSIM: 0.6301\n",
      "Epoch [55/200], Loss: 4039.1346, SSIM: 0.6292\n",
      "Epoch [56/200], Loss: 4028.2541, SSIM: 0.6291\n",
      "Epoch [57/200], Loss: 4021.0299, SSIM: 0.6297\n",
      "Epoch [58/200], Loss: 4020.0619, SSIM: 0.6303\n",
      "Epoch [59/200], Loss: 4019.8830, SSIM: 0.6283\n",
      "Epoch [60/200], Loss: 4016.0053, SSIM: 0.6308\n",
      "Epoch [61/200], Loss: 4015.5660, SSIM: 0.6306\n",
      "Epoch [62/200], Loss: 4024.6647, SSIM: 0.6310\n",
      "Epoch [63/200], Loss: 4018.1955, SSIM: 0.6305\n",
      "Epoch [64/200], Loss: 4012.3577, SSIM: 0.6307\n",
      "Epoch [65/200], Loss: 4009.2255, SSIM: 0.6319\n",
      "Epoch [66/200], Loss: 4007.2611, SSIM: 0.6321\n",
      "Epoch [67/200], Loss: 4007.1993, SSIM: 0.6323\n",
      "Epoch [68/200], Loss: 4007.5706, SSIM: 0.6314\n",
      "Epoch [69/200], Loss: 4007.2712, SSIM: 0.6322\n",
      "Epoch [70/200], Loss: 4010.5588, SSIM: 0.6314\n",
      "Epoch [71/200], Loss: 4004.4393, SSIM: 0.6333\n",
      "Epoch [72/200], Loss: 4004.1645, SSIM: 0.6330\n",
      "Epoch [73/200], Loss: 4004.7161, SSIM: 0.6318\n",
      "Epoch [74/200], Loss: 4007.9432, SSIM: 0.6334\n",
      "Epoch [75/200], Loss: 4014.4674, SSIM: 0.6324\n",
      "Epoch [76/200], Loss: 3999.6621, SSIM: 0.6325\n",
      "Epoch [77/200], Loss: 4006.0543, SSIM: 0.6332\n",
      "Epoch [78/200], Loss: 4032.2065, SSIM: 0.6310\n",
      "Epoch [79/200], Loss: 4007.0483, SSIM: 0.6322\n",
      "Epoch [80/200], Loss: 3999.6346, SSIM: 0.6330\n",
      "Epoch [81/200], Loss: 3996.3008, SSIM: 0.6334\n",
      "Epoch [82/200], Loss: 3994.0951, SSIM: 0.6328\n",
      "Epoch [83/200], Loss: 3990.4685, SSIM: 0.6342\n",
      "Epoch [84/200], Loss: 3993.6864, SSIM: 0.6345\n",
      "Epoch [85/200], Loss: 3991.8570, SSIM: 0.6345\n",
      "Epoch [86/200], Loss: 3998.6857, SSIM: 0.6329\n",
      "Epoch [87/200], Loss: 3994.8936, SSIM: 0.6343\n",
      "Epoch [88/200], Loss: 3987.6959, SSIM: 0.6354\n",
      "Epoch [89/200], Loss: 3995.0355, SSIM: 0.6340\n",
      "Epoch [90/200], Loss: 3993.1198, SSIM: 0.6340\n",
      "Epoch [91/200], Loss: 3985.2019, SSIM: 0.6344\n",
      "Epoch [92/200], Loss: 3992.2572, SSIM: 0.6345\n",
      "Epoch [93/200], Loss: 4004.5748, SSIM: 0.6344\n",
      "Epoch [94/200], Loss: 3991.3339, SSIM: 0.6339\n",
      "Epoch [95/200], Loss: 3985.3220, SSIM: 0.6346\n",
      "Epoch [96/200], Loss: 3983.9438, SSIM: 0.6353\n",
      "Epoch [97/200], Loss: 3984.8716, SSIM: 0.6351\n",
      "Epoch [98/200], Loss: 3984.9187, SSIM: 0.6357\n",
      "Epoch [99/200], Loss: 3987.8199, SSIM: 0.6338\n",
      "Epoch [100/200], Loss: 3994.2396, SSIM: 0.6332\n",
      "Epoch [101/200], Loss: 3995.7834, SSIM: 0.6331\n",
      "Epoch [102/200], Loss: 3993.8707, SSIM: 0.6343\n",
      "Epoch [103/200], Loss: 3984.5184, SSIM: 0.6347\n",
      "Epoch [104/200], Loss: 3980.0765, SSIM: 0.6359\n",
      "Epoch [105/200], Loss: 3980.9682, SSIM: 0.6352\n",
      "Epoch [106/200], Loss: 3983.8466, SSIM: 0.6349\n",
      "Epoch [107/200], Loss: 3984.7143, SSIM: 0.6348\n",
      "Epoch [108/200], Loss: 3979.9015, SSIM: 0.6356\n",
      "Epoch [109/200], Loss: 3978.0204, SSIM: 0.6358\n",
      "Epoch [110/200], Loss: 3986.4531, SSIM: 0.6346\n",
      "Epoch [111/200], Loss: 3978.7335, SSIM: 0.6357\n",
      "Epoch [112/200], Loss: 3978.2184, SSIM: 0.6360\n",
      "Epoch [113/200], Loss: 3978.6687, SSIM: 0.6350\n",
      "Epoch [114/200], Loss: 3984.6996, SSIM: 0.6339\n",
      "Epoch [115/200], Loss: 3983.8338, SSIM: 0.6359\n",
      "Epoch [116/200], Loss: 3978.9194, SSIM: 0.6352\n",
      "Epoch [117/200], Loss: 3979.7267, SSIM: 0.6355\n",
      "Epoch [118/200], Loss: 3981.2829, SSIM: 0.6352\n",
      "Epoch [119/200], Loss: 3981.0204, SSIM: 0.6353\n",
      "Epoch [120/200], Loss: 3977.3176, SSIM: 0.6361\n",
      "Epoch [121/200], Loss: 3978.6478, SSIM: 0.6351\n",
      "Epoch [122/200], Loss: 3973.3859, SSIM: 0.6367\n",
      "Epoch [123/200], Loss: 3974.2132, SSIM: 0.6357\n",
      "Epoch [124/200], Loss: 3980.4341, SSIM: 0.6349\n",
      "Epoch [125/200], Loss: 3975.6291, SSIM: 0.6358\n",
      "Epoch [126/200], Loss: 3975.2227, SSIM: 0.6360\n",
      "Epoch [127/200], Loss: 3981.3383, SSIM: 0.6354\n",
      "Epoch [128/200], Loss: 3979.2960, SSIM: 0.6363\n",
      "Epoch [129/200], Loss: 3975.3368, SSIM: 0.6360\n",
      "Epoch [130/200], Loss: 3973.8807, SSIM: 0.6367\n",
      "Epoch [131/200], Loss: 3973.5671, SSIM: 0.6362\n",
      "Epoch [132/200], Loss: 3976.4761, SSIM: 0.6370\n",
      "Epoch [133/200], Loss: 3975.0550, SSIM: 0.6364\n",
      "Epoch [134/200], Loss: 3980.0321, SSIM: 0.6356\n",
      "Epoch [135/200], Loss: 3968.6415, SSIM: 0.6373\n",
      "Epoch [136/200], Loss: 3966.3464, SSIM: 0.6370\n",
      "Epoch [137/200], Loss: 3975.4239, SSIM: 0.6366\n",
      "Epoch [138/200], Loss: 3968.7600, SSIM: 0.6369\n",
      "Epoch [139/200], Loss: 3982.1098, SSIM: 0.6356\n",
      "Epoch [140/200], Loss: 3983.4871, SSIM: 0.6351\n",
      "Epoch [141/200], Loss: 3969.7822, SSIM: 0.6365\n",
      "Epoch [142/200], Loss: 3971.9311, SSIM: 0.6359\n",
      "Epoch [143/200], Loss: 3969.5522, SSIM: 0.6366\n",
      "Epoch [144/200], Loss: 3968.2449, SSIM: 0.6369\n",
      "Epoch [145/200], Loss: 3965.8803, SSIM: 0.6375\n",
      "Epoch [146/200], Loss: 3969.1789, SSIM: 0.6358\n",
      "Epoch [147/200], Loss: 3975.2138, SSIM: 0.6364\n",
      "Epoch [148/200], Loss: 3968.9919, SSIM: 0.6365\n",
      "Epoch [149/200], Loss: 3967.3972, SSIM: 0.6368\n",
      "Epoch [150/200], Loss: 3971.5260, SSIM: 0.6365\n",
      "Epoch [151/200], Loss: 3965.6962, SSIM: 0.6378\n",
      "Epoch [152/200], Loss: 3965.7786, SSIM: 0.6373\n",
      "Epoch [153/200], Loss: 3965.9494, SSIM: 0.6377\n",
      "Epoch [154/200], Loss: 3967.3315, SSIM: 0.6372\n",
      "Epoch [155/200], Loss: 3966.7603, SSIM: 0.6375\n",
      "Epoch [156/200], Loss: 3966.5968, SSIM: 0.6374\n",
      "Epoch [157/200], Loss: 3969.1815, SSIM: 0.6373\n",
      "Epoch [158/200], Loss: 3968.4122, SSIM: 0.6373\n",
      "Epoch [159/200], Loss: 3968.6383, SSIM: 0.6372\n",
      "Epoch [160/200], Loss: 3965.6931, SSIM: 0.6377\n",
      "Epoch [161/200], Loss: 3963.1988, SSIM: 0.6374\n",
      "Epoch [162/200], Loss: 3964.9148, SSIM: 0.6370\n",
      "Epoch [163/200], Loss: 3970.5730, SSIM: 0.6369\n",
      "Epoch [164/200], Loss: 3977.2900, SSIM: 0.6366\n",
      "Epoch [165/200], Loss: 3972.7514, SSIM: 0.6380\n",
      "Epoch [166/200], Loss: 3964.5448, SSIM: 0.6382\n",
      "Epoch [167/200], Loss: 3962.5525, SSIM: 0.6377\n",
      "Epoch [168/200], Loss: 3962.6494, SSIM: 0.6373\n",
      "Epoch [169/200], Loss: 3963.9310, SSIM: 0.6376\n",
      "Epoch [170/200], Loss: 3962.4787, SSIM: 0.6369\n",
      "Epoch [171/200], Loss: 3965.5199, SSIM: 0.6371\n",
      "Epoch [172/200], Loss: 3961.7153, SSIM: 0.6381\n",
      "Epoch [173/200], Loss: 3959.7238, SSIM: 0.6386\n",
      "Epoch [174/200], Loss: 3960.9094, SSIM: 0.6377\n",
      "Epoch [175/200], Loss: 3962.5651, SSIM: 0.6375\n",
      "Epoch [176/200], Loss: 3962.1245, SSIM: 0.6375\n",
      "Epoch [177/200], Loss: 3962.4144, SSIM: 0.6376\n",
      "Epoch [178/200], Loss: 3960.9823, SSIM: 0.6378\n",
      "Epoch [179/200], Loss: 3960.9744, SSIM: 0.6377\n",
      "Epoch [180/200], Loss: 3959.3843, SSIM: 0.6385\n",
      "Epoch [181/200], Loss: 3958.1896, SSIM: 0.6380\n",
      "Epoch [182/200], Loss: 3963.0449, SSIM: 0.6383\n",
      "Epoch [183/200], Loss: 3964.2660, SSIM: 0.6369\n",
      "Epoch [184/200], Loss: 3959.3880, SSIM: 0.6384\n",
      "Epoch [185/200], Loss: 3961.9579, SSIM: 0.6377\n",
      "Epoch [186/200], Loss: 3970.7409, SSIM: 0.6372\n",
      "Epoch [187/200], Loss: 3964.4076, SSIM: 0.6377\n",
      "Epoch [188/200], Loss: 3958.2745, SSIM: 0.6379\n",
      "Epoch [189/200], Loss: 3958.7515, SSIM: 0.6382\n",
      "Epoch [190/200], Loss: 3963.9999, SSIM: 0.6378\n",
      "Epoch [191/200], Loss: 3954.8803, SSIM: 0.6389\n",
      "Epoch [192/200], Loss: 3967.1459, SSIM: 0.6374\n",
      "Epoch [193/200], Loss: 3963.0289, SSIM: 0.6374\n",
      "Epoch [194/200], Loss: 3963.2109, SSIM: 0.6372\n",
      "Epoch [195/200], Loss: 3958.5622, SSIM: 0.6384\n",
      "Epoch [196/200], Loss: 3959.8248, SSIM: 0.6380\n",
      "Epoch [197/200], Loss: 3960.5806, SSIM: 0.6376\n",
      "Epoch [198/200], Loss: 3956.5624, SSIM: 0.6388\n",
      "Epoch [199/200], Loss: 3953.3701, SSIM: 0.6387\n",
      "Epoch [200/200], Loss: 3954.6772, SSIM: 0.6388\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200  # Change as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    running_ssim = 0.0\n",
    "\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "\n",
    "        outputs = model(x_batch)  # Forward pass\n",
    "        loss = criterion(outputs, y_batch)  # Compute loss\n",
    "\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Compute SSIM (detach to avoid tracking gradients)\n",
    "        batch_ssim = ssim_metric(outputs.detach(), y_batch.detach())\n",
    "        running_ssim += batch_ssim.item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Print epoch loss\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}, SSIM: {running_ssim/len(train_loader):.4f}\")\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
